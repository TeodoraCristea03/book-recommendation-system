{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449e202e-2703-44b1-9179-e00a9658a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tcristea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation, cosine\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import sys, os\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ee90ec-2f9d-44d0-87b0-818257cb1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read and parse: goodread_books, goodread_interactions, book_id_map, my_rated_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6915b4dc-686a-4c92-8380-833951988625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_authors_dict():\n",
    "    authors = {}\n",
    "    with open(\"inputs/goodreads_book_authors.json\", 'r') as f:\n",
    "        while line := f.readline():\n",
    "            json_line = json.loads(line)\n",
    "            authors[json_line[\"author_id\"]] = json_line[\"name\"]\n",
    "    return authors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91d24f2-6324-4bf9-8b73-62dc72baca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_dict = read_authors_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608f7b57-350e-4ffc-a55a-ea0cd61029e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_fields(json_line, authors_dict):\n",
    "    return {\n",
    "        \"book_id\": json_line[\"book_id\"],\n",
    "        \"title\": json_line[\"title\"],\n",
    "        \"description\": json_line[\"description\"],\n",
    "        \"ratings_count\": json_line[\"ratings_count\"],\n",
    "        \"num_pages\": json_line[\"num_pages\"],\n",
    "        \"publication_year\": json_line[\"publication_year\"],\n",
    "        \"url\": json_line[\"url\"],\n",
    "        # \"image_url\": json_line[\"image_url\"],\n",
    "        \"average_rating\": json_line[\"average_rating\"],\n",
    "        \"authors\": \" \".join([authors_dict[x[\"author_id\"]] for x in json_line[\"authors\"]]),\n",
    "        \"publisher\": json_line[\"publisher\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a64c90-59ba-4a2d-90d1-f526806d02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_df(authors_dict, min_rating_count=1000):\n",
    "    parsed_books = []\n",
    "    with gzip.open(\"inputs/goodreads_books.json.gz\", 'r') as f:\n",
    "        while line := f.readline():\n",
    "            needed_fields = get_needed_fields(json.loads(line), authors_dict)\n",
    "            try:\n",
    "                ratings_count = int(needed_fields[\"ratings_count\"])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if ratings_count > min_rating_count:\n",
    "                parsed_books.append(needed_fields)\n",
    "    books = pd.DataFrame.from_dict(parsed_books)\n",
    "    books[\"ratings_count\"] = pd.to_numeric(books[\"ratings_count\"])\n",
    "    books[\"title\"] = books[\"title\"].str.replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True)\n",
    "    books[\"title\"] = books[\"title\"].str.lower()\n",
    "    books[\"title\"] = books[\"title\"].str.replace(\"\\s+\", \" \", regex=True)\n",
    "    books = books[books[\"title\"].str.len() > 0]\n",
    "    books[\"book_id\"] = pd.to_numeric( books[\"book_id\"])\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8e9d3e-c702-4290-a995-51475b78377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = get_books_df(authors_dict, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b36b654-5da6-464a-b1e8-760878b0d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6066819</td>\n",
       "      <td>best friends forever</td>\n",
       "      <td>Addie Downs and Valerie Adler were eight when ...</td>\n",
       "      <td>51184</td>\n",
       "      <td>368</td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/6066819-be...</td>\n",
       "      <td>3.49</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>Atria Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89375</td>\n",
       "      <td>90 minutes in heaven a true story of death and...</td>\n",
       "      <td>As he is driving home from a minister's confer...</td>\n",
       "      <td>68157</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/89375.90_M...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>Don Piper Cecil Murphey</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89376</td>\n",
       "      <td>heaven</td>\n",
       "      <td>What is Heaven really going to be like? What w...</td>\n",
       "      <td>7345</td>\n",
       "      <td>533</td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/89376.Heaven</td>\n",
       "      <td>4.26</td>\n",
       "      <td>Randy Alcorn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89377</td>\n",
       "      <td>penny from heaven</td>\n",
       "      <td>It's 1953 and 11-year-old Penny dreams of a su...</td>\n",
       "      <td>6949</td>\n",
       "      <td>288</td>\n",
       "      <td>2006</td>\n",
       "      <td>https://www.goodreads.com/book/show/89377.Penn...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>Jennifer L. Holm</td>\n",
       "      <td>Random House Books for Young Readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89378</td>\n",
       "      <td>dog heaven</td>\n",
       "      <td>In Newbery Medalist Cynthia Rylant's classic b...</td>\n",
       "      <td>1331</td>\n",
       "      <td>40</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/89378.Dog_...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>Cynthia Rylant</td>\n",
       "      <td>Blue Sky Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90935</th>\n",
       "      <td>335370</td>\n",
       "      <td>rose madder</td>\n",
       "      <td>A grimmer than Grimm fairy tale for our times-...</td>\n",
       "      <td>1201</td>\n",
       "      <td>420</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/335370.Ros...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>Viking Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90936</th>\n",
       "      <td>57064</td>\n",
       "      <td>hammerfall the gene wars 1</td>\n",
       "      <td>One of the most renowned figures in science fi...</td>\n",
       "      <td>1143</td>\n",
       "      <td>457</td>\n",
       "      <td>2002</td>\n",
       "      <td>https://www.goodreads.com/book/show/57064.Hamm...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>C.J. Cherryh</td>\n",
       "      <td>Eos / Harper Voyager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90937</th>\n",
       "      <td>7715664</td>\n",
       "      <td>sin undone demonica 5</td>\n",
       "      <td>HER TOUCH IS DEADLY\\nAs the only female Seminu...</td>\n",
       "      <td>23091</td>\n",
       "      <td>400</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.goodreads.com/book/show/7715664-si...</td>\n",
       "      <td>4.35</td>\n",
       "      <td>Larissa Ione</td>\n",
       "      <td>Grand Central Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90938</th>\n",
       "      <td>3106983</td>\n",
       "      <td>persepolis the story of a childhood and the st...</td>\n",
       "      <td>The Story of a Childhood and The Story of a Re...</td>\n",
       "      <td>1966</td>\n",
       "      <td>343</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://www.goodreads.com/book/show/3106983-pe...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>Marjane Satrapi Anjali Singh</td>\n",
       "      <td>Vintage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90939</th>\n",
       "      <td>1885730</td>\n",
       "      <td>joel and cat set the story straight</td>\n",
       "      <td></td>\n",
       "      <td>1094</td>\n",
       "      <td>240</td>\n",
       "      <td>2007</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885730.Jo...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Nick Earls Rebecca Sparrow</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90735 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_id                                              title   \n",
       "0      6066819                               best friends forever  \\\n",
       "1        89375  90 minutes in heaven a true story of death and...   \n",
       "2        89376                                             heaven   \n",
       "3        89377                                  penny from heaven   \n",
       "4        89378                                         dog heaven   \n",
       "...        ...                                                ...   \n",
       "90935   335370                                        rose madder   \n",
       "90936    57064                         hammerfall the gene wars 1   \n",
       "90937  7715664                              sin undone demonica 5   \n",
       "90938  3106983  persepolis the story of a childhood and the st...   \n",
       "90939  1885730                joel and cat set the story straight   \n",
       "\n",
       "                                             description  ratings_count   \n",
       "0      Addie Downs and Valerie Adler were eight when ...          51184  \\\n",
       "1      As he is driving home from a minister's confer...          68157   \n",
       "2      What is Heaven really going to be like? What w...           7345   \n",
       "3      It's 1953 and 11-year-old Penny dreams of a su...           6949   \n",
       "4      In Newbery Medalist Cynthia Rylant's classic b...           1331   \n",
       "...                                                  ...            ...   \n",
       "90935  A grimmer than Grimm fairy tale for our times-...           1201   \n",
       "90936  One of the most renowned figures in science fi...           1143   \n",
       "90937  HER TOUCH IS DEADLY\\nAs the only female Seminu...          23091   \n",
       "90938  The Story of a Childhood and The Story of a Re...           1966   \n",
       "90939                                                              1094   \n",
       "\n",
       "      num_pages publication_year   \n",
       "0           368             2009  \\\n",
       "1                                  \n",
       "2           533                    \n",
       "3           288             2006   \n",
       "4            40             1995   \n",
       "...         ...              ...   \n",
       "90935       420             1995   \n",
       "90936       457             2002   \n",
       "90937       400             2010   \n",
       "90938       343             2008   \n",
       "90939       240             2007   \n",
       "\n",
       "                                                     url average_rating   \n",
       "0      https://www.goodreads.com/book/show/6066819-be...           3.49  \\\n",
       "1      https://www.goodreads.com/book/show/89375.90_M...           3.91   \n",
       "2       https://www.goodreads.com/book/show/89376.Heaven           4.26   \n",
       "3      https://www.goodreads.com/book/show/89377.Penn...           3.98   \n",
       "4      https://www.goodreads.com/book/show/89378.Dog_...           4.43   \n",
       "...                                                  ...            ...   \n",
       "90935  https://www.goodreads.com/book/show/335370.Ros...           3.67   \n",
       "90936  https://www.goodreads.com/book/show/57064.Hamm...           3.62   \n",
       "90937  https://www.goodreads.com/book/show/7715664-si...           4.35   \n",
       "90938  https://www.goodreads.com/book/show/3106983-pe...           4.36   \n",
       "90939  https://www.goodreads.com/book/show/1885730.Jo...           3.78   \n",
       "\n",
       "                            authors                             publisher  \n",
       "0                   Jennifer Weiner                           Atria Books  \n",
       "1           Don Piper Cecil Murphey                                        \n",
       "2                      Randy Alcorn                                        \n",
       "3                  Jennifer L. Holm  Random House Books for Young Readers  \n",
       "4                    Cynthia Rylant                        Blue Sky Press  \n",
       "...                             ...                                   ...  \n",
       "90935                  Stephen King                          Viking Adult  \n",
       "90936                  C.J. Cherryh                  Eos / Harper Voyager  \n",
       "90937                  Larissa Ione              Grand Central Publishing  \n",
       "90938  Marjane Satrapi Anjali Singh                               Vintage  \n",
       "90939    Nick Earls Rebecca Sparrow                               Penguin  \n",
       "\n",
       "[90735 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32483a8-08e0-45dd-ae8d-447de390f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_csv_map():\n",
    "    csv_book_mapping = {}\n",
    "    first_line = True\n",
    "    with open(\"inputs/book_id_map.csv\", \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            csv_id, book_id = line.strip().split(\",\")\n",
    "            csv_book_mapping[int(csv_id)] = int(book_id)\n",
    "    return csv_book_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab95e017-2224-4a82-b045-ea963dd5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_csv_ids_map = get_books_csv_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d89c87-98b6-4d6c-ad69-8d61fc9f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_rated_books_df(books_df):\n",
    "    rated_books = []\n",
    "    first_line = True\n",
    "    with open(\"inputs/my_rated_books.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            book_id, rating = line.strip().split(\",\")\n",
    "            rated_books.append({\"book_id\": int(book_id), \"rating\": int(rating)})\n",
    "    books = pd.DataFrame.from_dict(rated_books, dtype = int)\n",
    "    books_augmented = books_df.merge(books, how=\"inner\", on=\"book_id\")\n",
    "    return books_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89edb6f-ac35-4aca-8ee7-1649e5e109de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rate_books_df = get_my_rated_books_df(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be58d65-6c82-4cf6-b761-36dcdee5397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_users(my_rate_books_df, same_books_ratio):\n",
    "    users = {}\n",
    "    first_line = True\n",
    "    book_set = set(my_rate_books_df[\"book_id\"])\n",
    "    with open(\"inputs/goodreads_interactions.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            user_id, csv_id, _, rating, _ = line.strip().split(\",\")\n",
    "            book_id = books_csv_ids_map.get(int(csv_id))\n",
    "            if int(book_id) in book_set:\n",
    "                if int(user_id) not in users:\n",
    "                    users[int(user_id)] = 1\n",
    "                else:\n",
    "                    users[int(user_id)] +=1\n",
    "    return set([k for k in users if users[k] > len(my_rate_books_df)/same_books_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b808f4c-d363-49cc-b0a0-ea47285e6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users = get_filtered_users(my_rate_books_df, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ccc0c32-f4ce-4c65-a785-64e4342c3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interactions_df(filtered_users):\n",
    "    interactions_lists = []\n",
    "    first_line = True       \n",
    "    with open(\"inputs/goodreads_interactions.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            user_id, csv_id, _, rating, _ = line.strip().split(\",\")\n",
    "            book_id = books_csv_ids_map.get(int(csv_id))\n",
    "            if int(user_id) in filtered_users:\n",
    "                interactions_lists.append({\"user_id\": int(user_id), \"book_id\": int(book_id), \"rating\": int(rating)})\n",
    "\n",
    "    interactions_df = pd.DataFrame.from_dict(interactions_lists, dtype=int)\n",
    "    # interactions_df = interactions_df[interactions_df[\"book_id\"].isin(filtered_users)]\n",
    "    return interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59623720-94ca-497c-80b9-208648eed1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df_initial = get_interactions_df(filtered_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b794409-e44a-40b1-a523-60ecf1eb52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df_initial\n",
    "for i, row in my_rate_books_df[[\"book_id\", \"rating\"]].iterrows():\n",
    "    interactions_df = pd.concat([interactions_df, pd.DataFrame([{\"user_id\": 1, \"book_id\": row[\"book_id\"], \"rating\": row[\"rating\"]}])], ignore_index=True)\n",
    "interactions_df = interactions_df.sort_values(by=\"user_id\").reset_index(drop=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0737dbf5-0f1a-4e02-a30b-d0916401e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef881d58-512f-493e-ac72-4e258c1d9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_books_df(books_df):\n",
    "    def removeNonAscii(s):\n",
    "        return \"\".join(i for i in s if  ord(i)<128)\n",
    "    def make_lower_case(text):\n",
    "        return text.lower()\n",
    "    def remove_stop_words(text):\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    def remove_punctuation(text):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    def full_normalize(text):\n",
    "        text = re.sub(\"[^a-zA-Z0-9 ]\", \"\", text)\n",
    "        text = re.sub(\"\\s+\", \" \", text)\n",
    "        text = removeNonAscii(text)\n",
    "        text = make_lower_case(text)\n",
    "        text = remove_stop_words(text)\n",
    "        return remove_punctuation(text)\n",
    "        \n",
    "    aux_df = books_df.copy()\n",
    "    aux_df[\"title\"] = aux_df[\"title\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"title\"].str.len() > 0]\n",
    "    aux_df[\"description\"] = aux_df[\"description\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"description\"].str.len() > 0]\n",
    "    aux_df[\"authors\"] = aux_df[\"authors\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"authors\"].str.len() > 0]\n",
    "    aux_df[\"publisher\"] = aux_df[\"publisher\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"publisher\"].str.len() > 0]\n",
    "    # TODO migh need/not need this for average_rating\n",
    "    # aux_df[\"average_rating\"] = aux_df[\"average_rating\"].apply(full_normalize)\n",
    "    # aux_df = aux_df[aux_df[\"average_rating\"].str.len() > 0]\n",
    "    \n",
    "    \n",
    "    return aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e56c80-a5e5-44c4-a0c9-52db68dcb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df_initial = books_df\n",
    "books_df = preprocess_books_df(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de29d811-75e5-4241-96e2-1ed42a94cfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6066819</td>\n",
       "      <td>best friends forever</td>\n",
       "      <td>addie downs valerie adler eight first met deci...</td>\n",
       "      <td>51184</td>\n",
       "      <td>368</td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/6066819-be...</td>\n",
       "      <td>3.49</td>\n",
       "      <td>jennifer weiner</td>\n",
       "      <td>atria books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89377</td>\n",
       "      <td>penny heaven</td>\n",
       "      <td>1953 11yearold penny dreams summer butter peca...</td>\n",
       "      <td>6949</td>\n",
       "      <td>288</td>\n",
       "      <td>2006</td>\n",
       "      <td>https://www.goodreads.com/book/show/89377.Penn...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>jennifer l holm</td>\n",
       "      <td>random house books young readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89378</td>\n",
       "      <td>dog heaven</td>\n",
       "      <td>newbery medalist cynthia rylants classic bests...</td>\n",
       "      <td>1331</td>\n",
       "      <td>40</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/89378.Dog_...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>cynthia rylant</td>\n",
       "      <td>blue sky press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25317381</td>\n",
       "      <td>smoke</td>\n",
       "      <td>amazon best book yeara goodreads best book mon...</td>\n",
       "      <td>1537</td>\n",
       "      <td>340</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://www.goodreads.com/book/show/25317381-s...</td>\n",
       "      <td>3.69</td>\n",
       "      <td>catherine mckenzie</td>\n",
       "      <td>lake union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22642971</td>\n",
       "      <td>body electric</td>\n",
       "      <td>future world peaceella shepherd dedicated life...</td>\n",
       "      <td>1525</td>\n",
       "      <td>351</td>\n",
       "      <td>2014</td>\n",
       "      <td>https://www.goodreads.com/book/show/22642971-t...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>beth revis</td>\n",
       "      <td>scripturient books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90934</th>\n",
       "      <td>7657484</td>\n",
       "      <td>superman earth one volume 1</td>\n",
       "      <td>forget everything know man steel brace stagger...</td>\n",
       "      <td>13221</td>\n",
       "      <td>134</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.goodreads.com/book/show/7657484-su...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>j michael straczynski shane davis sandra hope ...</td>\n",
       "      <td>dc comics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90935</th>\n",
       "      <td>335370</td>\n",
       "      <td>rose madder</td>\n",
       "      <td>grimmer grimm fairy tale timesfrom master maca...</td>\n",
       "      <td>1201</td>\n",
       "      <td>420</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/335370.Ros...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>stephen king</td>\n",
       "      <td>viking adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90936</th>\n",
       "      <td>57064</td>\n",
       "      <td>hammerfall gene wars 1</td>\n",
       "      <td>one renowned figures science fiction cj cherry...</td>\n",
       "      <td>1143</td>\n",
       "      <td>457</td>\n",
       "      <td>2002</td>\n",
       "      <td>https://www.goodreads.com/book/show/57064.Hamm...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>cj cherryh</td>\n",
       "      <td>eos harper voyager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90937</th>\n",
       "      <td>7715664</td>\n",
       "      <td>sin undone demonica 5</td>\n",
       "      <td>touch deadlyas female seminus demon ever born ...</td>\n",
       "      <td>23091</td>\n",
       "      <td>400</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.goodreads.com/book/show/7715664-si...</td>\n",
       "      <td>4.35</td>\n",
       "      <td>larissa ione</td>\n",
       "      <td>grand central publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90938</th>\n",
       "      <td>3106983</td>\n",
       "      <td>persepolis story childhood story return</td>\n",
       "      <td>story childhood story returnthe intelligent ou...</td>\n",
       "      <td>1966</td>\n",
       "      <td>343</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://www.goodreads.com/book/show/3106983-pe...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>marjane satrapi anjali singh</td>\n",
       "      <td>vintage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66087 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id                                    title   \n",
       "0       6066819                     best friends forever  \\\n",
       "3         89377                             penny heaven   \n",
       "4         89378                               dog heaven   \n",
       "5      25317381                                    smoke   \n",
       "7      22642971                            body electric   \n",
       "...         ...                                      ...   \n",
       "90934   7657484              superman earth one volume 1   \n",
       "90935    335370                              rose madder   \n",
       "90936     57064                   hammerfall gene wars 1   \n",
       "90937   7715664                    sin undone demonica 5   \n",
       "90938   3106983  persepolis story childhood story return   \n",
       "\n",
       "                                             description  ratings_count   \n",
       "0      addie downs valerie adler eight first met deci...          51184  \\\n",
       "3      1953 11yearold penny dreams summer butter peca...           6949   \n",
       "4      newbery medalist cynthia rylants classic bests...           1331   \n",
       "5      amazon best book yeara goodreads best book mon...           1537   \n",
       "7      future world peaceella shepherd dedicated life...           1525   \n",
       "...                                                  ...            ...   \n",
       "90934  forget everything know man steel brace stagger...          13221   \n",
       "90935  grimmer grimm fairy tale timesfrom master maca...           1201   \n",
       "90936  one renowned figures science fiction cj cherry...           1143   \n",
       "90937  touch deadlyas female seminus demon ever born ...          23091   \n",
       "90938  story childhood story returnthe intelligent ou...           1966   \n",
       "\n",
       "      num_pages publication_year   \n",
       "0           368             2009  \\\n",
       "3           288             2006   \n",
       "4            40             1995   \n",
       "5           340             2015   \n",
       "7           351             2014   \n",
       "...         ...              ...   \n",
       "90934       134             2010   \n",
       "90935       420             1995   \n",
       "90936       457             2002   \n",
       "90937       400             2010   \n",
       "90938       343             2008   \n",
       "\n",
       "                                                     url average_rating   \n",
       "0      https://www.goodreads.com/book/show/6066819-be...           3.49  \\\n",
       "3      https://www.goodreads.com/book/show/89377.Penn...           3.98   \n",
       "4      https://www.goodreads.com/book/show/89378.Dog_...           4.43   \n",
       "5      https://www.goodreads.com/book/show/25317381-s...           3.69   \n",
       "7      https://www.goodreads.com/book/show/22642971-t...           3.71   \n",
       "...                                                  ...            ...   \n",
       "90934  https://www.goodreads.com/book/show/7657484-su...           3.90   \n",
       "90935  https://www.goodreads.com/book/show/335370.Ros...           3.67   \n",
       "90936  https://www.goodreads.com/book/show/57064.Hamm...           3.62   \n",
       "90937  https://www.goodreads.com/book/show/7715664-si...           4.35   \n",
       "90938  https://www.goodreads.com/book/show/3106983-pe...           4.36   \n",
       "\n",
       "                                                 authors   \n",
       "0                                        jennifer weiner  \\\n",
       "3                                        jennifer l holm   \n",
       "4                                         cynthia rylant   \n",
       "5                                     catherine mckenzie   \n",
       "7                                             beth revis   \n",
       "...                                                  ...   \n",
       "90934  j michael straczynski shane davis sandra hope ...   \n",
       "90935                                       stephen king   \n",
       "90936                                         cj cherryh   \n",
       "90937                                       larissa ione   \n",
       "90938                       marjane satrapi anjali singh   \n",
       "\n",
       "                              publisher  \n",
       "0                           atria books  \n",
       "3      random house books young readers  \n",
       "4                        blue sky press  \n",
       "5                            lake union  \n",
       "7                    scripturient books  \n",
       "...                                 ...  \n",
       "90934                         dc comics  \n",
       "90935                      viking adult  \n",
       "90936                eos harper voyager  \n",
       "90937          grand central publishing  \n",
       "90938                           vintage  \n",
       "\n",
       "[66087 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2165945-7519-49f6-9338-07015b0e712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Recommender systems have a problem known as user cold-start, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences.\n",
    "#     For this reason, we are keeping in the dataset only users with at least 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2419f900-ab4c-4263-bff0-39c388d82cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['user_id', 'book_id']).size().groupby('user_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "602c2e2d-9808-44c1-8041-15955138bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 625\n"
     ]
    }
   ],
   "source": [
    "print('# users: %d' % len(users_interactions_count_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50347560-5ebd-4119-a347-9676d893df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5f6e9a4-98c3-4519-a429-7c3c00d3bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users with at least 5 interactions: 625\n"
     ]
    }
   ],
   "source": [
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "211e8293-cad2-4a01-85b2-5983cb3ff118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfecffc6-6e41-4fff-b7fd-cdf6a3aa0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'user_id',\n",
    "               right_on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc1a09b-d099-4cd7-be1a-868f13aefbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions from users with at least 5 interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51d19776-058b-4af7-a1f1-d30fa9c5d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our User Interactions dataset is complete and all users have at least 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a7d5b74-ed46-4cd2-99f0-c1b955d4b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. We aggregate all the interactions a user had with a book (review) by a weighted sum of interaction-type strenght.\n",
    "    # The weight in our case is the rating (0-5)\n",
    "    # We then apply a log transformation to smooth the distribution\n",
    "# TODO: We can also skip this step, as all our interactions are unique (user_id+book_id grouping). This step will only\n",
    "    # apply the log transformation in our case\n",
    "    # to skip this step just use\n",
    "    # interactions_full_df = interactions_from_selected_users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a71aab6e-1c3e-4b83-bbb1-06a764e8c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "321572e3-955d-4418-9fdf-3b5b9326b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['user_id', 'book_id'])['rating'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3783f2d-7186-43af-a663-97fca5290af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd52af6e-e5a8-4b16-ad44-f252a6dc342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2373</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>142540</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>227729</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>395851</td>\n",
       "      <td>2.321928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>395875</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id    rating\n",
       "0        1     2373  2.584963\n",
       "1        1   142540  2.584963\n",
       "2        1   227729  2.000000\n",
       "3        1   395851  2.321928\n",
       "4        1   395875  2.584963"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88c908fc-d10b-470f-8b65-e16eed304a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create our TF-IDF vector\n",
    "    # Ignoring stopwords (words with no semantics) from English\n",
    "    # Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus\n",
    "# TODO:\n",
    "    # - We can adjust the 5000 vector size and check for better/worse results (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a303c3-7ef1-42ae-9e28-556261a795d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d675991c-1e75-4855-a43d-82850bb9b976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.5, max_features=5000, min_df=0.003, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.5, max_features=5000, min_df=0.003, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.5, max_features=5000, min_df=0.003, ngram_range=(1, 2),\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31874045-653f-42e8-b21c-befd8d4d1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids = books_df['book_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ac0f38f-522f-4f14-9495-56bdb4e7e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our TF-IDF we use: title, description, ratings_count, num_pages, publication_year, average_rating, authors and publisher\n",
    "# TODO:\n",
    "    # - We can only use title, description as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7f31700-9f6e-4d8b-8e5e-8215be67e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(books_df['title'] + \" \" + books_df['description'] + \" \" + books_df['ratings_count'].astype(str)+ \" \" + \\\n",
    "                                       books_df['num_pages'].astype(str) + \" \" +  books_df['publication_year'].astype(str) + \" \" + \\\n",
    "                                       books_df['average_rating'].astype(str) + \" \" + books_df['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ed2abcc-8d3c-461e-90e1-1ac166f62ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66087x4656 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3779569 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2bb343d-2b2f-45a9-8f90-066198237b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.0. To create user profiles, we take all the books the user interacted with and average them. The average is weighted\n",
    "    # by the rating. The books the user has rated the highest will have a higher strangth in the final user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe99636d-935a-4446-8ba1-9d6e4d91749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_profile(book_id):\n",
    "    idx = book_ids.index(book_id)\n",
    "    book_profile = tfidf_matrix[idx:idx+1]\n",
    "    return book_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "daf1ff0c-8823-4945-b7ca-e5ce2eb56ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_profiles(book_ids):\n",
    "    book_profiles_list = [get_book_profile(x) for x in book_ids]\n",
    "    book_profiles = scipy.sparse.vstack(book_profiles_list)\n",
    "    return book_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f8fac98-9a34-42f6-ae36-2d22d90a01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profile(user_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[user_id]\n",
    "    user_book_profiles = get_book_profiles(interactions_person_df['book_id'])\n",
    "    \n",
    "    user_book_strengths = np.array(interactions_person_df['rating']).reshape(-1,1)\n",
    "    # print(user_book_strengths)\n",
    "    # print(user_id)\n",
    "        \n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    aux_copy = user_book_strengths.copy()\n",
    "    aux_copy[aux_copy == 0] = 1\n",
    "    user_book_strengths_weighted_avg = np.sum(user_book_profiles.multiply(aux_copy), axis=0) / np.sum(user_book_strengths)\n",
    "    # print(user_book_strengths_weighted_avg)\n",
    "    # print(np.asarray(user_book_strengths_weighted_avg))\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(np.asarray(user_book_strengths_weighted_avg))\n",
    "    return user_profile_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d9f4f9f-1119-4f5d-9397-f34cddecde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = interactions_train_df[interactions_train_df['book_id'] \\\n",
    "                                                   .isin(books_df['book_id'])].set_index('user_id')\n",
    "    user_profiles = {}\n",
    "    for user_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[user_id] = build_users_profile(user_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0f7c33d-228c-4068-9fb7-8db6896a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1. Split user interactions in 2 datasets: train (80%) and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6022a91f-50cf-4f15-8cce-e4dbfc85f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "#                                    stratify=interactions_full_df['user_id'], \n",
    "#                                    test_size=0.20,\n",
    "#                                    random_state=42)\n",
    "interactions_train_df = interactions_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df21e6a5-02d0-4dc9-a4f0-746dd49fb689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "# print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f497cfc-2eb1-432f-b43b-7c9bce568462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Running this takes considerable time: X mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce1709fa-001b-4567-bd28-ce61e0228973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_profiles = build_users_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a3268263-6326-4c32-b440-bc6a05328350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b5dd344e-313c-4ad7-9938-429c0a6142bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Let's take a look at the user profile for user_id = 1. This is a vector of 5000 tokens together with\n",
    "    # how relevant is that token for user_id=1 (tokens are both unigrams and bigrams)\n",
    "    # We can sort the tokens by their relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c086722-238b-4793-bddf-7e06d205a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myprofile = user_profiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "288dcec8-ce27-468d-9dd1-10ecb839f5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.03305183, 0.02433519, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a01b47a4-de6e-489e-8a84-77c6c2d5cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4466)\n"
     ]
    }
   ],
   "source": [
    "print(myprofile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "562b863b-2ec3-449b-b069-118aa96d9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "325efe99-4d17-4d60-8764-c03189d1cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>throne</td>\n",
       "      <td>0.317354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>0.292706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarah</td>\n",
       "      <td>0.223369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assassin</td>\n",
       "      <td>0.199357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shatter</td>\n",
       "      <td>0.191613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vampire</td>\n",
       "      <td>0.180695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unspeakable</td>\n",
       "      <td>0.145393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>court</td>\n",
       "      <td>0.143830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diaries</td>\n",
       "      <td>0.120552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>series</td>\n",
       "      <td>0.108410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>smith</td>\n",
       "      <td>0.102641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>must</td>\n",
       "      <td>0.100772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brother</td>\n",
       "      <td>0.099551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story two</td>\n",
       "      <td>0.095421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.092457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>desert</td>\n",
       "      <td>0.089875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>terrifying</td>\n",
       "      <td>0.089196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fight</td>\n",
       "      <td>0.086997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>brothers</td>\n",
       "      <td>0.086992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>new</td>\n",
       "      <td>0.086869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  relevance\n",
       "0        throne   0.317354\n",
       "1         glass   0.292706\n",
       "2         sarah   0.223369\n",
       "3      assassin   0.199357\n",
       "4       shatter   0.191613\n",
       "5       vampire   0.180695\n",
       "6   unspeakable   0.145393\n",
       "7         court   0.143830\n",
       "8       diaries   0.120552\n",
       "9        series   0.108410\n",
       "10        smith   0.102641\n",
       "11         must   0.100772\n",
       "12      brother   0.099551\n",
       "13    story two   0.095421\n",
       "14         1999   0.092457\n",
       "15       desert   0.089875\n",
       "16   terrifying   0.089196\n",
       "17        fight   0.086997\n",
       "18     brothers   0.086992\n",
       "19          new   0.086869"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[1].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "158c51cf-0851-4b7f-9950-8c66ce0975eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, books_df=None):\n",
    "        self.book_ids = book_ids\n",
    "        self.books_df = books_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_books_to_user_profile(self, user_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all book profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[user_id], tfidf_matrix)\n",
    "        #Gets the top similar books\n",
    "        similar_indices = cosine_similarities.argsort().flatten()\n",
    "        #Sort the similar books by similarity\n",
    "        similar_items = sorted([(book_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_books(self, user_id, books_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_books = self._get_similar_books_to_user_profile(user_id)\n",
    "        #Ignores books the user has already rated\n",
    "        similar_books_filtered = list(filter(lambda x: x[0] not in books_to_ignore, similar_books))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_books_filtered, columns=['book_id', 'recStrength'])\n",
    "\n",
    "        if verbose:\n",
    "            if self.books_df is None:\n",
    "                raise Exception('\"books_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.books_df, how = 'left', \n",
    "                                                          left_on = 'book_id', \n",
    "                                                          right_on = 'book_id')[['recStrength', 'book_id', 'title', 'description', 'ratings_count', \\\n",
    "                                                                                 'url', 'average_rating', 'authors', 'publisher', \\\n",
    "                                                                                'publication_year', 'num_pages']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7b8e77e-57c4-4b0e-9d0b-be1259476718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Before evaluating the model, lets see what books are recommended for user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f9d8025-2095-4775-b760-680e967f3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_interacted(user_id, interactions_df):\n",
    "    interacted_books = interactions_df.loc[user_id]['book_id']\n",
    "    return set(interacted_books if type(interacted_books) == pd.Series else [interacted_books])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b3ff3c6-5587-45a9-a066-3170e6c70a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_1_recommendations = content_based_recommender_model.recommend_books(1, get_books_interacted(1, interactions_df.set_index('user_id')), 20, True)\n",
    "user_1_recommendations = content_based_recommender_model.recommend_books(1, {}, 20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9dd9c71-c3d9-4daa-a2b3-403b7a2426e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. TODO: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cf0e4d3e-af50-447a-8c45-f671b5ee8ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recStrength</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>url</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>num_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457660</td>\n",
       "      <td>13565676</td>\n",
       "      <td>assassin empire throne glass 05</td>\n",
       "      <td>celaena sardothien assassin everything place c...</td>\n",
       "      <td>18049</td>\n",
       "      <td>https://www.goodreads.com/book/show/13565676-t...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2012</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443082</td>\n",
       "      <td>33590260</td>\n",
       "      <td>untitled throne glass 7</td>\n",
       "      <td>final installment throne glass series</td>\n",
       "      <td>1190</td>\n",
       "      <td>https://www.goodreads.com/book/show/33590260-u...</td>\n",
       "      <td>4.63</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens books</td>\n",
       "      <td>2018</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438609</td>\n",
       "      <td>28260587</td>\n",
       "      <td>empire storms throne glass 5</td>\n",
       "      <td>kingdoms collidethe long path throne begun ael...</td>\n",
       "      <td>70571</td>\n",
       "      <td>https://www.goodreads.com/book/show/28260587-e...</td>\n",
       "      <td>4.58</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury childrens books</td>\n",
       "      <td>2016</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427192</td>\n",
       "      <td>13415554</td>\n",
       "      <td>assassin pirate lord throne glass 01</td>\n",
       "      <td>throne glass novellaon remote island tropical ...</td>\n",
       "      <td>21641</td>\n",
       "      <td>https://www.goodreads.com/book/show/13415554-t...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury childrens</td>\n",
       "      <td>2012</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426003</td>\n",
       "      <td>18333581</td>\n",
       "      <td>assassin healer throne glass 02</td>\n",
       "      <td>meet assassin beautiful defiant destined great...</td>\n",
       "      <td>11992</td>\n",
       "      <td>https://www.goodreads.com/book/show/18333581-t...</td>\n",
       "      <td>4.21</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury publishing</td>\n",
       "      <td>2013</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.423650</td>\n",
       "      <td>18006496</td>\n",
       "      <td>queen shadows throne glass 4</td>\n",
       "      <td>queen returnedeveryone celaena sardothien love...</td>\n",
       "      <td>106182</td>\n",
       "      <td>https://www.goodreads.com/book/show/18006496-q...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2015</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.419664</td>\n",
       "      <td>17167166</td>\n",
       "      <td>crown midnight throne glass 2</td>\n",
       "      <td>line never crossed breachedit puts entire cast...</td>\n",
       "      <td>169307</td>\n",
       "      <td>https://www.goodreads.com/book/show/17167166-c...</td>\n",
       "      <td>4.49</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2013</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.419450</td>\n",
       "      <td>23599075</td>\n",
       "      <td>throne glass throne glass 1</td>\n",
       "      <td>nothing coincidence everything purpose meant c...</td>\n",
       "      <td>3236</td>\n",
       "      <td>https://www.goodreads.com/book/show/23599075-t...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2013</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.409438</td>\n",
       "      <td>7896527</td>\n",
       "      <td>throne glass throne glass 1</td>\n",
       "      <td>alternate cover edition found serving year har...</td>\n",
       "      <td>295609</td>\n",
       "      <td>https://www.goodreads.com/book/show/7896527-th...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2012</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.403699</td>\n",
       "      <td>13574861</td>\n",
       "      <td>throne glass throne glass 1</td>\n",
       "      <td>alternate cover edition asin serving year hard...</td>\n",
       "      <td>9687</td>\n",
       "      <td>https://www.goodreads.com/book/show/13574861-t...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>sarah j maas</td>\n",
       "      <td>bloomsbury usa childrens</td>\n",
       "      <td>2012</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recStrength   book_id                                 title   \n",
       "0     0.457660  13565676       assassin empire throne glass 05  \\\n",
       "1     0.443082  33590260               untitled throne glass 7   \n",
       "2     0.438609  28260587          empire storms throne glass 5   \n",
       "3     0.427192  13415554  assassin pirate lord throne glass 01   \n",
       "4     0.426003  18333581       assassin healer throne glass 02   \n",
       "5     0.423650  18006496          queen shadows throne glass 4   \n",
       "6     0.419664  17167166         crown midnight throne glass 2   \n",
       "7     0.419450  23599075           throne glass throne glass 1   \n",
       "8     0.409438   7896527           throne glass throne glass 1   \n",
       "9     0.403699  13574861           throne glass throne glass 1   \n",
       "\n",
       "                                         description  ratings_count   \n",
       "0  celaena sardothien assassin everything place c...          18049  \\\n",
       "1              final installment throne glass series           1190   \n",
       "2  kingdoms collidethe long path throne begun ael...          70571   \n",
       "3  throne glass novellaon remote island tropical ...          21641   \n",
       "4  meet assassin beautiful defiant destined great...          11992   \n",
       "5  queen returnedeveryone celaena sardothien love...         106182   \n",
       "6  line never crossed breachedit puts entire cast...         169307   \n",
       "7  nothing coincidence everything purpose meant c...           3236   \n",
       "8  alternate cover edition found serving year har...         295609   \n",
       "9  alternate cover edition asin serving year hard...           9687   \n",
       "\n",
       "                                                 url average_rating   \n",
       "0  https://www.goodreads.com/book/show/13565676-t...           4.42  \\\n",
       "1  https://www.goodreads.com/book/show/33590260-u...           4.63   \n",
       "2  https://www.goodreads.com/book/show/28260587-e...           4.58   \n",
       "3  https://www.goodreads.com/book/show/13415554-t...           4.23   \n",
       "4  https://www.goodreads.com/book/show/18333581-t...           4.21   \n",
       "5  https://www.goodreads.com/book/show/18006496-q...           4.60   \n",
       "6  https://www.goodreads.com/book/show/17167166-c...           4.49   \n",
       "7  https://www.goodreads.com/book/show/23599075-t...           4.23   \n",
       "8  https://www.goodreads.com/book/show/7896527-th...           4.23   \n",
       "9  https://www.goodreads.com/book/show/13574861-t...           4.23   \n",
       "\n",
       "        authors                       publisher publication_year num_pages  \n",
       "0  sarah j maas        bloomsbury usa childrens             2012        94  \n",
       "1  sarah j maas  bloomsbury usa childrens books             2018       702  \n",
       "2  sarah j maas      bloomsbury childrens books             2016       693  \n",
       "3  sarah j maas            bloomsbury childrens             2012        70  \n",
       "4  sarah j maas           bloomsbury publishing             2013        40  \n",
       "5  sarah j maas        bloomsbury usa childrens             2015       648  \n",
       "6  sarah j maas        bloomsbury usa childrens             2013       418  \n",
       "7  sarah j maas        bloomsbury usa childrens             2013       404  \n",
       "8  sarah j maas        bloomsbury usa childrens             2012       404  \n",
       "9  sarah j maas        bloomsbury usa childrens             2012       432  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_1_recommendations[user_1_recommendations[\"book_id\"] == user_1_recommendations[\"recStrength\"].min()]\n",
    "# user_1_recommendations[user_1_recommendations[\"ratings_count\"] > 10000].head(30)\n",
    "user_1_recommendations[user_1_recommendations[\"book_id\"] == 2373].empty\n",
    "user_1_recommendations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0e48e388-309a-4c23-a2de-4f93756d5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = user_1_recommendations[[\"recStrength\", \"book_id\"]].copy()\n",
    "aux[\"recStrength\"] = aux[\"recStrength\"] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f05030d-6900-4bf4-8ab3-2ee3f621b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(user_recommendations, my_rate_books_df, metric=\"Content-Based\"):\n",
    "    predictions = []\n",
    "    target = []\n",
    "    predictions_to_ret = {}\n",
    "    for i, row in my_rate_books_df.iterrows():\n",
    "        target.append(row[\"rating\"])\n",
    "        # predictions.append(svd.predict(1, row[\"book_id\"]).est)\n",
    "        predictions.append(float(user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]][\"recStrength\"].iloc[0]) if \\\n",
    "                          not user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]].empty else 4.02)\n",
    "        predictions_to_ret[row[\"book_id\"]] = (float(user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]][\"recStrength\"].iloc[0]) if \\\n",
    "                          not user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]].empty else 4.02, row[\"rating\"])\n",
    "        # print(row)\n",
    "    prediction= pd.DataFrame(predictions).T\n",
    "    target_prediction = pd.DataFrame(target).T\n",
    "\n",
    "    # 1. Compute RMSE\n",
    "    RS = np.sqrt(np.mean((prediction-target_prediction)**2))\n",
    "    print(\"Valoarea RMSE pentru predictia de tip {} este: {}\".format(metric, RS))\n",
    "\n",
    "    # 2. Compute MAE\n",
    "    mae = mean_absolute_error(target_prediction, prediction)\n",
    "    print(\"Valoarea MAE pentru predictia de tip {} este: {}\".format(metric, mae))\n",
    "\n",
    "    TPs = 0\n",
    "    FNs = 0\n",
    "    # The number of relevant items are the items with actual rating greater or equal to 3.5.\n",
    "    threshold = 3.5\n",
    "     # Find the relevant items using the threshold\n",
    "    relevant_items = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if target_prediction.values[i, j] > threshold:\n",
    "                relevant_items.append((i, j))\n",
    "\n",
    "    # Compute K\n",
    "    k = len(relevant_items)\n",
    "\n",
    "    # Recommended items @ k\n",
    "    recommended_items_at_k = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if prediction.values[i, j] > threshold:\n",
    "                recommended_items_at_k.append((i, j))\n",
    "\n",
    "     # Recommended and Relevant items @ k (Intersection)\n",
    "    recomm_and_relevant_items_at_k = list(set(relevant_items) & set(recommended_items_at_k))\n",
    "\n",
    "    # Compute Precision @ K\n",
    "    precision_at_k = len(recomm_and_relevant_items_at_k) / len(recommended_items_at_k)\n",
    "\n",
    "    print(\"Precision at k={}, for prediction using metric {}, is: {}\".format(k, metric, precision_at_k))\n",
    "\n",
    "    # Compute Recall @ K\n",
    "    recall_at_k = len(recomm_and_relevant_items_at_k) / len(relevant_items)\n",
    "\n",
    "    print(\"Recall at k={} for prediction using metric {}, is: {}\".format(k, metric, recall_at_k))\n",
    "\n",
    "    # Compute F1 score @ K\n",
    "    f1_score_at_k = 2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k)\n",
    "\n",
    "    print(\"F1 Score at k={}, for prediction using metric {}, is: {}\".format(k, metric, f1_score_at_k))\n",
    "    return predictions_to_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3ae09cb1-ab03-4bfb-b4db-50a987e1d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valoarea RMSE pentru predictia de tip Content-Based este: 1.451388584164388\n",
      "Valoarea MAE pentru predictia de tip Content-Based este: 1.1930588591264004\n",
      "Precision at k=22, for prediction using metric Content-Based, is: 0.8666666666666667\n",
      "Recall at k=22 for prediction using metric Content-Based, is: 0.5909090909090909\n",
      "F1 Score at k=22, for prediction using metric Content-Based, is: 0.7027027027027029\n"
     ]
    }
   ],
   "source": [
    "content_based_predictions = evaluate_predictions(aux, my_rate_books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "655a0871-52d3-40be-b214-a5036bf92735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13104080: (2.6969770317900092, 5),\n",
       " 395875: (2.8247334348241755, 5),\n",
       " 1169808: (3.692906927282708, 5),\n",
       " 10429045: (2.3976474680371425, 4),\n",
       " 13565676: (4.576600828467035, 4),\n",
       " 23766634: (3.196370620052771, 3),\n",
       " 13419891: (3.614129202702699, 5),\n",
       " 142540: (1.9270116545053873, 5),\n",
       " 395922: (3.4699940919769547, 5),\n",
       " 20613470: (3.9117361648899522, 5),\n",
       " 29008738: (2.4728692617307715, 5),\n",
       " 18006496: (4.236503104889732, 4),\n",
       " 13415554: (4.271920132072667, 5),\n",
       " 17331518: (3.0052962306506856, 5),\n",
       " 17167166: (4.196642057447526, 4),\n",
       " 28260587: (4.386086052082112, 5),\n",
       " 31450852: (4.02, 5),\n",
       " 395851: (3.7805349790448624, 4),\n",
       " 13188676: (3.1469505320354556, 5),\n",
       " 18333581: (4.2600332471557545, 4),\n",
       " 2373: (4.02, 5),\n",
       " 16096824: (2.8351461703389154, 5),\n",
       " 17927395: (3.7198854582095837, 3),\n",
       " 7896527: (4.0943754959021055, 4),\n",
       " 227729: (4.02, 3)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "635b89d4-d83f-4da9-8c95-5897ad2b372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0527d9a5-dd39-4944-a3af-c7804ec43da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_predictions = {13104080: (5, 5),\n",
    " 395875: (4.623304667079186, 5),\n",
    " 1169808: (4.700428011513711, 5),\n",
    " 10429045: (4.69773755557114, 4),\n",
    " 13565676: (4.476495798083327, 4),\n",
    " 23766634: (3.735443965722295, 3),\n",
    " 13419891: (4.714168739575217, 5),\n",
    " 142540: (3.184105938606115, 5),\n",
    " 395922: (4.704848494599006, 5),\n",
    " 20613470: (4.203287233539408, 5),\n",
    " 29008738: (3.4050771012860905, 5),\n",
    " 18006496: (4.378874537661045, 4),\n",
    " 13415554: (4.598957728959821, 5),\n",
    " 17331518: (4.149879583368218, 5),\n",
    " 17167166: (4.379493769462175, 4),\n",
    " 28260587: (3.9556038446562205, 5),\n",
    " 31450852: (3.6987781565071796, 5),\n",
    " 395851: (4.663370677685508, 4),\n",
    " 13188676: (4.914707767958816, 5),\n",
    " 18333581: (4.452522676938357, 4),\n",
    " 2373: (3.7060847380882143, 5),\n",
    " 16096824: (4.787223584601609, 5),\n",
    " 17927395: (4.127090922908268, 3),\n",
    " 7896527: (4.431188944194735, 4),\n",
    " 227729: (3.4173784513395544, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ea78072-18c7-4957-826e-b6a35128d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_model_predictions(cotent_based_predictions, item_based_predictions, cb_weight, ib_weight, metric=\"Hybrid\"):\n",
    "    predictions = []\n",
    "    target = []\n",
    "    for key, value in cotent_based_predictions.items():\n",
    "        target.append(value[1])\n",
    "        pred_value = (value[0] * cb_weight + item_based_predictions[key][0] * ib_weight) / (cb_weight + ib_weight)\n",
    "        predictions.append(pred_value)\n",
    "        # print(row)\n",
    "    prediction= pd.DataFrame(predictions).T\n",
    "    target_prediction = pd.DataFrame(target).T\n",
    "\n",
    "    # 1. Compute RMSE\n",
    "    RS = np.sqrt(np.mean((prediction-target_prediction)**2))\n",
    "    print(\"Valoarea RMSE pentru predictia de tip {} este: {}\".format(metric, RS))\n",
    "\n",
    "    # 2. Compute MAE\n",
    "    mae = mean_absolute_error(target_prediction, prediction)\n",
    "    print(\"Valoarea MAE pentru predictia de tip {} este: {}\".format(metric, mae))\n",
    "    \n",
    "\n",
    "    TPs = 0\n",
    "    FNs = 0\n",
    "    # The number of relevant items are the items with actual rating greater or equal to 3.5.\n",
    "    threshold = 3.5\n",
    "     # Find the relevant items using the threshold\n",
    "    relevant_items = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if target_prediction.values[i, j] > threshold:\n",
    "                relevant_items.append((i, j))\n",
    "\n",
    "    # Compute K\n",
    "    k = len(relevant_items)\n",
    "\n",
    "    # Recommended items @ k\n",
    "    recommended_items_at_k = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if prediction.values[i, j] > threshold:\n",
    "                recommended_items_at_k.append((i, j))\n",
    "\n",
    "     # Recommended and Relevant items @ k (Intersection)\n",
    "    recomm_and_relevant_items_at_k = list(set(relevant_items) & set(recommended_items_at_k))\n",
    "\n",
    "    # Compute Precision @ K\n",
    "    precision_at_k = len(recomm_and_relevant_items_at_k) / len(recommended_items_at_k)\n",
    "\n",
    "    print(\"Precision at k={}, for prediction using metric {}, is: {}\".format(k, metric, precision_at_k))\n",
    "\n",
    "    # Compute Recall @ K\n",
    "    recall_at_k = len(recomm_and_relevant_items_at_k) / len(relevant_items)\n",
    "\n",
    "    print(\"Recall at k={} for prediction using metric {}, is: {}\".format(k, metric, recall_at_k))\n",
    "\n",
    "    # Compute F1 score @ K\n",
    "    f1_score_at_k = 2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k)\n",
    "\n",
    "    print(\"F1 Score at k={}, for prediction using metric {}, is: {}\".format(k, metric, f1_score_at_k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0433b99b-6030-4bc9-bb27-3236f789466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valoarea RMSE pentru predictia de tip Hybrid este: 0.8601555606034893\n",
      "Valoarea MAE pentru predictia de tip Hybrid este: 0.734683225673875\n",
      "Precision at k=22, for prediction using metric Hybrid, is: 0.8695652173913043\n",
      "Recall at k=22 for prediction using metric Hybrid, is: 0.9090909090909091\n",
      "F1 Score at k=22, for prediction using metric Hybrid, is: 0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "evaluate_hybrid_model_predictions(content_based_predictions, svd_predictions, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef724b7c-d29b-4eab-8b06-c4ab4ff4c296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0ae3a-7897-42e1-a322-5a976992595a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
