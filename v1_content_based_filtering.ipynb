{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449e202e-2703-44b1-9179-e00a9658a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tcristea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation, cosine\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "import sys, os\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ee90ec-2f9d-44d0-87b0-818257cb1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read and parse: goodread_books, goodread_interactions, book_id_map, my_rated_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6915b4dc-686a-4c92-8380-833951988625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_authors_dict():\n",
    "    authors = {}\n",
    "    with open(\"inputs/goodreads_book_authors.json\", 'r') as f:\n",
    "        while line := f.readline():\n",
    "            json_line = json.loads(line)\n",
    "            authors[json_line[\"author_id\"]] = json_line[\"name\"]\n",
    "    return authors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91d24f2-6324-4bf9-8b73-62dc72baca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_dict = read_authors_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608f7b57-350e-4ffc-a55a-ea0cd61029e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_fields(json_line, authors_dict):\n",
    "    return {\n",
    "        \"book_id\": json_line[\"book_id\"],\n",
    "        \"title\": json_line[\"title\"],\n",
    "        \"description\": json_line[\"description\"],\n",
    "        \"ratings_count\": json_line[\"ratings_count\"],\n",
    "        \"num_pages\": json_line[\"num_pages\"],\n",
    "        \"publication_year\": json_line[\"publication_year\"],\n",
    "        \"url\": json_line[\"url\"],\n",
    "        # \"image_url\": json_line[\"image_url\"],\n",
    "        \"average_rating\": json_line[\"average_rating\"],\n",
    "        \"authors\": \" \".join([authors_dict[x[\"author_id\"]] for x in json_line[\"authors\"]]),\n",
    "        \"publisher\": json_line[\"publisher\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a64c90-59ba-4a2d-90d1-f526806d02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_df(authors_dict, min_rating_count=1000):\n",
    "    parsed_books = []\n",
    "    with gzip.open(\"inputs/goodreads_books.json.gz\", 'r') as f:\n",
    "        while line := f.readline():\n",
    "            needed_fields = get_needed_fields(json.loads(line), authors_dict)\n",
    "            try:\n",
    "                ratings_count = int(needed_fields[\"ratings_count\"])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if ratings_count > min_rating_count:\n",
    "                parsed_books.append(needed_fields)\n",
    "    books = pd.DataFrame.from_dict(parsed_books)\n",
    "    books[\"ratings_count\"] = pd.to_numeric(books[\"ratings_count\"])\n",
    "    books[\"title\"] = books[\"title\"].str.replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True)\n",
    "    books[\"title\"] = books[\"title\"].str.lower()\n",
    "    books[\"title\"] = books[\"title\"].str.replace(\"\\s+\", \" \", regex=True)\n",
    "    books = books[books[\"title\"].str.len() > 0]\n",
    "    books[\"book_id\"] = pd.to_numeric( books[\"book_id\"])\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8e9d3e-c702-4290-a995-51475b78377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = get_books_df(authors_dict, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b36b654-5da6-464a-b1e8-760878b0d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6066819</td>\n",
       "      <td>best friends forever</td>\n",
       "      <td>Addie Downs and Valerie Adler were eight when ...</td>\n",
       "      <td>51184</td>\n",
       "      <td>368</td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/6066819-be...</td>\n",
       "      <td>3.49</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>Atria Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89375</td>\n",
       "      <td>90 minutes in heaven a true story of death and...</td>\n",
       "      <td>As he is driving home from a minister's confer...</td>\n",
       "      <td>68157</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/89375.90_M...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>Don Piper Cecil Murphey</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89376</td>\n",
       "      <td>heaven</td>\n",
       "      <td>What is Heaven really going to be like? What w...</td>\n",
       "      <td>7345</td>\n",
       "      <td>533</td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/89376.Heaven</td>\n",
       "      <td>4.26</td>\n",
       "      <td>Randy Alcorn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89377</td>\n",
       "      <td>penny from heaven</td>\n",
       "      <td>It's 1953 and 11-year-old Penny dreams of a su...</td>\n",
       "      <td>6949</td>\n",
       "      <td>288</td>\n",
       "      <td>2006</td>\n",
       "      <td>https://www.goodreads.com/book/show/89377.Penn...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>Jennifer L. Holm</td>\n",
       "      <td>Random House Books for Young Readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89378</td>\n",
       "      <td>dog heaven</td>\n",
       "      <td>In Newbery Medalist Cynthia Rylant's classic b...</td>\n",
       "      <td>1331</td>\n",
       "      <td>40</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/89378.Dog_...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>Cynthia Rylant</td>\n",
       "      <td>Blue Sky Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90935</th>\n",
       "      <td>335370</td>\n",
       "      <td>rose madder</td>\n",
       "      <td>A grimmer than Grimm fairy tale for our times-...</td>\n",
       "      <td>1201</td>\n",
       "      <td>420</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://www.goodreads.com/book/show/335370.Ros...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>Viking Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90936</th>\n",
       "      <td>57064</td>\n",
       "      <td>hammerfall the gene wars 1</td>\n",
       "      <td>One of the most renowned figures in science fi...</td>\n",
       "      <td>1143</td>\n",
       "      <td>457</td>\n",
       "      <td>2002</td>\n",
       "      <td>https://www.goodreads.com/book/show/57064.Hamm...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>C.J. Cherryh</td>\n",
       "      <td>Eos / Harper Voyager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90937</th>\n",
       "      <td>7715664</td>\n",
       "      <td>sin undone demonica 5</td>\n",
       "      <td>HER TOUCH IS DEADLY\\nAs the only female Seminu...</td>\n",
       "      <td>23091</td>\n",
       "      <td>400</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://www.goodreads.com/book/show/7715664-si...</td>\n",
       "      <td>4.35</td>\n",
       "      <td>Larissa Ione</td>\n",
       "      <td>Grand Central Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90938</th>\n",
       "      <td>3106983</td>\n",
       "      <td>persepolis the story of a childhood and the st...</td>\n",
       "      <td>The Story of a Childhood and The Story of a Re...</td>\n",
       "      <td>1966</td>\n",
       "      <td>343</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://www.goodreads.com/book/show/3106983-pe...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>Marjane Satrapi Anjali Singh</td>\n",
       "      <td>Vintage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90939</th>\n",
       "      <td>1885730</td>\n",
       "      <td>joel and cat set the story straight</td>\n",
       "      <td></td>\n",
       "      <td>1094</td>\n",
       "      <td>240</td>\n",
       "      <td>2007</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885730.Jo...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Nick Earls Rebecca Sparrow</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90735 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_id                                              title   \n",
       "0      6066819                               best friends forever  \\\n",
       "1        89375  90 minutes in heaven a true story of death and...   \n",
       "2        89376                                             heaven   \n",
       "3        89377                                  penny from heaven   \n",
       "4        89378                                         dog heaven   \n",
       "...        ...                                                ...   \n",
       "90935   335370                                        rose madder   \n",
       "90936    57064                         hammerfall the gene wars 1   \n",
       "90937  7715664                              sin undone demonica 5   \n",
       "90938  3106983  persepolis the story of a childhood and the st...   \n",
       "90939  1885730                joel and cat set the story straight   \n",
       "\n",
       "                                             description  ratings_count   \n",
       "0      Addie Downs and Valerie Adler were eight when ...          51184  \\\n",
       "1      As he is driving home from a minister's confer...          68157   \n",
       "2      What is Heaven really going to be like? What w...           7345   \n",
       "3      It's 1953 and 11-year-old Penny dreams of a su...           6949   \n",
       "4      In Newbery Medalist Cynthia Rylant's classic b...           1331   \n",
       "...                                                  ...            ...   \n",
       "90935  A grimmer than Grimm fairy tale for our times-...           1201   \n",
       "90936  One of the most renowned figures in science fi...           1143   \n",
       "90937  HER TOUCH IS DEADLY\\nAs the only female Seminu...          23091   \n",
       "90938  The Story of a Childhood and The Story of a Re...           1966   \n",
       "90939                                                              1094   \n",
       "\n",
       "      num_pages publication_year   \n",
       "0           368             2009  \\\n",
       "1                                  \n",
       "2           533                    \n",
       "3           288             2006   \n",
       "4            40             1995   \n",
       "...         ...              ...   \n",
       "90935       420             1995   \n",
       "90936       457             2002   \n",
       "90937       400             2010   \n",
       "90938       343             2008   \n",
       "90939       240             2007   \n",
       "\n",
       "                                                     url average_rating   \n",
       "0      https://www.goodreads.com/book/show/6066819-be...           3.49  \\\n",
       "1      https://www.goodreads.com/book/show/89375.90_M...           3.91   \n",
       "2       https://www.goodreads.com/book/show/89376.Heaven           4.26   \n",
       "3      https://www.goodreads.com/book/show/89377.Penn...           3.98   \n",
       "4      https://www.goodreads.com/book/show/89378.Dog_...           4.43   \n",
       "...                                                  ...            ...   \n",
       "90935  https://www.goodreads.com/book/show/335370.Ros...           3.67   \n",
       "90936  https://www.goodreads.com/book/show/57064.Hamm...           3.62   \n",
       "90937  https://www.goodreads.com/book/show/7715664-si...           4.35   \n",
       "90938  https://www.goodreads.com/book/show/3106983-pe...           4.36   \n",
       "90939  https://www.goodreads.com/book/show/1885730.Jo...           3.78   \n",
       "\n",
       "                            authors                             publisher  \n",
       "0                   Jennifer Weiner                           Atria Books  \n",
       "1           Don Piper Cecil Murphey                                        \n",
       "2                      Randy Alcorn                                        \n",
       "3                  Jennifer L. Holm  Random House Books for Young Readers  \n",
       "4                    Cynthia Rylant                        Blue Sky Press  \n",
       "...                             ...                                   ...  \n",
       "90935                  Stephen King                          Viking Adult  \n",
       "90936                  C.J. Cherryh                  Eos / Harper Voyager  \n",
       "90937                  Larissa Ione              Grand Central Publishing  \n",
       "90938  Marjane Satrapi Anjali Singh                               Vintage  \n",
       "90939    Nick Earls Rebecca Sparrow                               Penguin  \n",
       "\n",
       "[90735 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32483a8-08e0-45dd-ae8d-447de390f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_csv_map():\n",
    "    csv_book_mapping = {}\n",
    "    first_line = True\n",
    "    with open(\"inputs/book_id_map.csv\", \"r\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            csv_id, book_id = line.strip().split(\",\")\n",
    "            csv_book_mapping[int(csv_id)] = int(book_id)\n",
    "    return csv_book_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab95e017-2224-4a82-b045-ea963dd5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_csv_ids_map = get_books_csv_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d89c87-98b6-4d6c-ad69-8d61fc9f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_rated_books_df(books_df):\n",
    "    rated_books = []\n",
    "    first_line = True\n",
    "    with open(\"inputs/my_rated_books.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            book_id, rating = line.strip().split(\",\")\n",
    "            rated_books.append({\"book_id\": int(book_id), \"rating\": int(rating)})\n",
    "    books = pd.DataFrame.from_dict(rated_books, dtype = int)\n",
    "    books_augmented = books_df.merge(books, how=\"inner\", on=\"book_id\")\n",
    "    return books_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89edb6f-ac35-4aca-8ee7-1649e5e109de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rate_books_df = get_my_rated_books_df(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be58d65-6c82-4cf6-b761-36dcdee5397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_users(my_rate_books_df, same_books_ratio):\n",
    "    users = {}\n",
    "    first_line = True\n",
    "    book_set = set(my_rate_books_df[\"book_id\"])\n",
    "    with open(\"inputs/goodreads_interactions.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            user_id, csv_id, _, rating, _ = line.strip().split(\",\")\n",
    "            book_id = books_csv_ids_map.get(int(csv_id))\n",
    "            if int(book_id) in book_set:\n",
    "                if int(user_id) not in users:\n",
    "                    users[int(user_id)] = 1\n",
    "                else:\n",
    "                    users[int(user_id)] +=1\n",
    "    return set([k for k in users if users[k] > len(my_rate_books_df)/same_books_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b808f4c-d363-49cc-b0a0-ea47285e6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users = get_filtered_users(my_rate_books_df, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ccc0c32-f4ce-4c65-a785-64e4342c3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interactions_df(filtered_users):\n",
    "    interactions_lists = []\n",
    "    first_line = True       \n",
    "    with open(\"inputs/goodreads_interactions.csv\") as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if first_line:\n",
    "                first_line = False\n",
    "                continue\n",
    "            user_id, csv_id, _, rating, _ = line.strip().split(\",\")\n",
    "            book_id = books_csv_ids_map.get(int(csv_id))\n",
    "            if int(user_id) in filtered_users:\n",
    "                interactions_lists.append({\"user_id\": int(user_id), \"book_id\": int(book_id), \"rating\": int(rating)})\n",
    "\n",
    "    interactions_df = pd.DataFrame.from_dict(interactions_lists, dtype=int)\n",
    "    # interactions_df = interactions_df[interactions_df[\"book_id\"].isin(filtered_users)]\n",
    "    return interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59623720-94ca-497c-80b9-208648eed1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df_initial = get_interactions_df(filtered_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b794409-e44a-40b1-a523-60ecf1eb52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df_initial\n",
    "for i, row in my_rate_books_df[[\"book_id\", \"rating\"]].iterrows():\n",
    "    interactions_df = pd.concat([interactions_df, pd.DataFrame([{\"user_id\": 1, \"book_id\": row[\"book_id\"], \"rating\": row[\"rating\"]}])], ignore_index=True)\n",
    "interactions_df = interactions_df.sort_values(by=\"user_id\").reset_index(drop=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0737dbf5-0f1a-4e02-a30b-d0916401e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef881d58-512f-493e-ac72-4e258c1d9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_books_df(books_df):\n",
    "    def removeNonAscii(s):\n",
    "        return \"\".join(i for i in s if  ord(i)<128)\n",
    "    def make_lower_case(text):\n",
    "        return text.lower()\n",
    "    def remove_stop_words(text):\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    def remove_punctuation(text):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    def full_normalize(text):\n",
    "        text = re.sub(\"[^a-zA-Z0-9 ]\", \"\", text)\n",
    "        text = re.sub(\"\\s+\", \" \", text)\n",
    "        text = removeNonAscii(text)\n",
    "        text = make_lower_case(text)\n",
    "        text = remove_stop_words(text)\n",
    "        return remove_punctuation(text)\n",
    "        \n",
    "    aux_df = books_df.copy()\n",
    "    aux_df[\"title\"] = aux_df[\"title\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"title\"].str.len() > 0]\n",
    "    aux_df[\"description\"] = aux_df[\"description\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"description\"].str.len() > 0]\n",
    "    aux_df[\"authors\"] = aux_df[\"authors\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"authors\"].str.len() > 0]\n",
    "    aux_df[\"publisher\"] = aux_df[\"publisher\"].apply(full_normalize)\n",
    "    aux_df = aux_df[aux_df[\"publisher\"].str.len() > 0]\n",
    "    # TODO migh need/not need this for average_rating\n",
    "    # aux_df[\"average_rating\"] = aux_df[\"average_rating\"].apply(full_normalize)\n",
    "    # aux_df = aux_df[aux_df[\"average_rating\"].str.len() > 0]\n",
    "    \n",
    "    \n",
    "    return aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e56c80-a5e5-44c4-a0c9-52db68dcb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df_initial = books_df\n",
    "books_df = preprocess_books_df(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2165945-7519-49f6-9338-07015b0e712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Recommender systems have a problem known as user cold-start, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences.\n",
    "#     For this reason, we are keeping in the dataset only users with at least 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2419f900-ab4c-4263-bff0-39c388d82cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['user_id', 'book_id']).size().groupby('user_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "602c2e2d-9808-44c1-8041-15955138bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 625\n"
     ]
    }
   ],
   "source": [
    "print('# users: %d' % len(users_interactions_count_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50347560-5ebd-4119-a347-9676d893df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f6e9a4-98c3-4519-a429-7c3c00d3bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users with at least 5 interactions: 625\n"
     ]
    }
   ],
   "source": [
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "211e8293-cad2-4a01-85b2-5983cb3ff118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfecffc6-6e41-4fff-b7fd-cdf6a3aa0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'user_id',\n",
    "               right_on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cc1a09b-d099-4cd7-be1a-868f13aefbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions from users with at least 5 interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51d19776-058b-4af7-a1f1-d30fa9c5d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our User Interactions dataset is complete and all users have at least 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a7d5b74-ed46-4cd2-99f0-c1b955d4b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. We aggregate all the interactions a user had with a book (review) by a weighted sum of interaction-type strenght.\n",
    "    # The weight in our case is the rating (0-5)\n",
    "    # We then apply a log transformation to smooth the distribution\n",
    "# TODO: We can also skip this step, as all our interactions are unique (user_id+book_id grouping). This step will only\n",
    "    # apply the log transformation in our case\n",
    "    # to skip this step just use\n",
    "    # interactions_full_df = interactions_from_selected_users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a71aab6e-1c3e-4b83-bbb1-06a764e8c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "321572e3-955d-4418-9fdf-3b5b9326b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['user_id', 'book_id'])['rating'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3783f2d-7186-43af-a663-97fca5290af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd52af6e-e5a8-4b16-ad44-f252a6dc342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2373</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>142540</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>227729</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>395851</td>\n",
       "      <td>2.321928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>395875</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id    rating\n",
       "0        1     2373  2.584963\n",
       "1        1   142540  2.584963\n",
       "2        1   227729  2.000000\n",
       "3        1   395851  2.321928\n",
       "4        1   395875  2.584963"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88c908fc-d10b-470f-8b65-e16eed304a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create our TF-IDF vector\n",
    "    # Ignoring stopwords (words with no semantics) from English\n",
    "    # Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus\n",
    "# TODO:\n",
    "    # - We can adjust the 5000 vector size and check for better/worse results (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a303c3-7ef1-42ae-9e28-556261a795d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31874045-653f-42e8-b21c-befd8d4d1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids = books_df['book_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ac0f38f-522f-4f14-9495-56bdb4e7e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our TF-IDF we use: title, description, ratings_count, num_pages, publication_year, average_rating, authors and publisher\n",
    "# TODO:\n",
    "    # - We can only use title, description as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7f31700-9f6e-4d8b-8e5e-8215be67e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(books_df['title'] + \"\" + books_df['description'] + books_df['ratings_count'].astype(str)+ \\\n",
    "                                       books_df['num_pages'].astype(str) +  books_df['publication_year'].astype(str) + \\\n",
    "                                       books_df['average_rating'].astype(str) + books_df['authors'] +  books_df['publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ed2abcc-8d3c-461e-90e1-1ac166f62ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66087x4189 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3389769 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2bb343d-2b2f-45a9-8f90-066198237b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.0. To create user profiles, we take all the books the user interacted with and average them. The average is weighted\n",
    "    # by the rating. The books the user has rated the highest will have a higher strangth in the final user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe99636d-935a-4446-8ba1-9d6e4d91749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_profile(book_id):\n",
    "    idx = book_ids.index(book_id)\n",
    "    book_profile = tfidf_matrix[idx:idx+1]\n",
    "    return book_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daf1ff0c-8823-4945-b7ca-e5ce2eb56ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_profiles(book_ids):\n",
    "    book_profiles_list = [get_book_profile(x) for x in book_ids]\n",
    "    book_profiles = scipy.sparse.vstack(book_profiles_list)\n",
    "    return book_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f8fac98-9a34-42f6-ae36-2d22d90a01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profile(user_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[user_id]\n",
    "    user_book_profiles = get_book_profiles(interactions_person_df['book_id'])\n",
    "    \n",
    "    user_book_strengths = np.array(interactions_person_df['rating']).reshape(-1,1)\n",
    "    # print(user_book_strengths)\n",
    "    # print(user_id)\n",
    "        \n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    aux_copy = user_book_strengths.copy()\n",
    "    aux_copy[aux_copy == 0] = 1\n",
    "    user_book_strengths_weighted_avg = np.sum(user_book_profiles.multiply(aux_copy), axis=0) / np.sum(user_book_strengths)\n",
    "    # print(user_book_strengths_weighted_avg)\n",
    "    # print(np.asarray(user_book_strengths_weighted_avg))\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(np.asarray(user_book_strengths_weighted_avg))\n",
    "    return user_profile_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d9f4f9f-1119-4f5d-9397-f34cddecde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = interactions_train_df[interactions_train_df['book_id'] \\\n",
    "                                                   .isin(books_df['book_id'])].set_index('user_id')\n",
    "    user_profiles = {}\n",
    "    for user_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[user_id] = build_users_profile(user_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0f7c33d-228c-4068-9fb7-8db6896a76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1. Split user interactions in 2 datasets: train (80%) and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6022a91f-50cf-4f15-8cce-e4dbfc85f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "#                                    stratify=interactions_full_df['user_id'], \n",
    "#                                    test_size=0.20,\n",
    "#                                    random_state=42)\n",
    "interactions_train_df = interactions_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df21e6a5-02d0-4dc9-a4f0-746dd49fb689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 2878532\n"
     ]
    }
   ],
   "source": [
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "# print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f497cfc-2eb1-432f-b43b-7c9bce568462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Running this takes considerable time: X mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce1709fa-001b-4567-bd28-ce61e0228973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_profiles = build_users_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3268263-6326-4c32-b440-bc6a05328350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5dd344e-313c-4ad7-9938-429c0a6142bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Let's take a look at the user profile for user_id = 1. This is a vector of 5000 tokens together with\n",
    "    # how relevant is that token for user_id=1 (tokens are both unigrams and bigrams)\n",
    "    # We can sort the tokens by their relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c086722-238b-4793-bddf-7e06d205a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myprofile = user_profiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a01b47a4-de6e-489e-8a84-77c6c2d5cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4189)\n"
     ]
    }
   ],
   "source": [
    "print(myprofile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "562b863b-2ec3-449b-b069-118aa96d9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "325efe99-4d17-4d60-8764-c03189d1cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass</td>\n",
       "      <td>0.308601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>throne</td>\n",
       "      <td>0.308308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assassin</td>\n",
       "      <td>0.213427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shatter</td>\n",
       "      <td>0.196741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vampire</td>\n",
       "      <td>0.191831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>childrens</td>\n",
       "      <td>0.173639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unspeakable</td>\n",
       "      <td>0.152813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>court</td>\n",
       "      <td>0.152549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>usa</td>\n",
       "      <td>0.130375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diaries</td>\n",
       "      <td>0.128588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>series</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>publishers</td>\n",
       "      <td>0.113567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>must</td>\n",
       "      <td>0.106199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>brother</td>\n",
       "      <td>0.104842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>story two</td>\n",
       "      <td>0.102173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>desert</td>\n",
       "      <td>0.096546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>terrifying</td>\n",
       "      <td>0.094858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>brothers</td>\n",
       "      <td>0.092191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>new</td>\n",
       "      <td>0.090943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>assassins</td>\n",
       "      <td>0.089325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  relevance\n",
       "0         glass   0.308601\n",
       "1        throne   0.308308\n",
       "2      assassin   0.213427\n",
       "3       shatter   0.196741\n",
       "4       vampire   0.191831\n",
       "5     childrens   0.173639\n",
       "6   unspeakable   0.152813\n",
       "7         court   0.152549\n",
       "8           usa   0.130375\n",
       "9       diaries   0.128588\n",
       "10       series   0.113615\n",
       "11   publishers   0.113567\n",
       "12         must   0.106199\n",
       "13      brother   0.104842\n",
       "14    story two   0.102173\n",
       "15       desert   0.096546\n",
       "16   terrifying   0.094858\n",
       "17     brothers   0.092191\n",
       "18          new   0.090943\n",
       "19    assassins   0.089325"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[1].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "158c51cf-0851-4b7f-9950-8c66ce0975eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, books_df=None):\n",
    "        self.book_ids = book_ids\n",
    "        self.books_df = books_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_books_to_user_profile(self, user_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all book profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[user_id], tfidf_matrix)\n",
    "        #Gets the top similar books\n",
    "        similar_indices = cosine_similarities.argsort().flatten()\n",
    "        #Sort the similar books by similarity\n",
    "        similar_items = sorted([(book_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_books(self, user_id, books_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_books = self._get_similar_books_to_user_profile(user_id)\n",
    "        #Ignores books the user has already rated\n",
    "        similar_books_filtered = list(filter(lambda x: x[0] not in books_to_ignore, similar_books))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_books_filtered, columns=['book_id', 'recStrength'])\n",
    "\n",
    "        if verbose:\n",
    "            if self.books_df is None:\n",
    "                raise Exception('\"books_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.books_df, how = 'left', \n",
    "                                                          left_on = 'book_id', \n",
    "                                                          right_on = 'book_id')[['recStrength', 'book_id', 'title', 'ratings_count', \\\n",
    "                                                                                 'url', 'average_rating', 'authors', 'publisher', \\\n",
    "                                                                                'publication_year', 'num_pages']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7b8e77e-57c4-4b0e-9d0b-be1259476718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Before evaluating the model, lets see what books are recommended for user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5f9d8025-2095-4775-b760-680e967f3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_interacted(user_id, interactions_df):\n",
    "    interacted_books = interactions_df.loc[user_id]['book_id']\n",
    "    return set(interacted_books if type(interacted_books) == pd.Series else [interacted_books])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7b3ff3c6-5587-45a9-a066-3170e6c70a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_1_recommendations = content_based_recommender_model.recommend_books(1, get_books_interacted(1, interactions_df.set_index('user_id')), 20, True)\n",
    "user_1_recommendations = content_based_recommender_model.recommend_books(1, {}, 20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f9dd9c71-c3d9-4daa-a2b3-403b7a2426e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. TODO: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cf0e4d3e-af50-447a-8c45-f671b5ee8ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_1_recommendations[user_1_recommendations[\"book_id\"] == user_1_recommendations[\"recStrength\"].min()]\n",
    "# user_1_recommendations[user_1_recommendations[\"ratings_count\"] > 10000].head(30)\n",
    "user_1_recommendations[user_1_recommendations[\"book_id\"] == 2373].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0e48e388-309a-4c23-a2de-4f93756d5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = user_1_recommendations[[\"recStrength\", \"book_id\"]].copy()\n",
    "aux[\"recStrength\"] = aux[\"recStrength\"] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9f05030d-6900-4bf4-8ab3-2ee3f621b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(user_recommendations, my_rate_books_df, metric=\"Content-Based\"):\n",
    "    predictions = []\n",
    "    target = []\n",
    "    predictions_to_ret = {}\n",
    "    for i, row in my_rate_books_df.iterrows():\n",
    "        target.append(row[\"rating\"])\n",
    "        # predictions.append(svd.predict(1, row[\"book_id\"]).est)\n",
    "        predictions.append(float(user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]][\"recStrength\"].iloc[0]) if \\\n",
    "                          not user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]].empty else 4.02)\n",
    "        predictions_to_ret[row[\"book_id\"]] = (float(user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]][\"recStrength\"].iloc[0]) if \\\n",
    "                          not user_recommendations[user_recommendations[\"book_id\"] == row[\"book_id\"]].empty else 4.02, row[\"rating\"])\n",
    "        # print(row)\n",
    "    prediction= pd.DataFrame(predictions).T\n",
    "    target_prediction = pd.DataFrame(target).T\n",
    "    \n",
    "\n",
    "    TPs = 0\n",
    "    FNs = 0\n",
    "    # The number of relevant items are the items with actual rating greater or equal to 3.5.\n",
    "    threshold = 3.5\n",
    "     # Find the relevant items using the threshold\n",
    "    relevant_items = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if target_prediction.values[i, j] > threshold:\n",
    "                relevant_items.append((i, j))\n",
    "\n",
    "    # Compute K\n",
    "    k = len(relevant_items)\n",
    "\n",
    "    # Recommended items @ k\n",
    "    recommended_items_at_k = []\n",
    "    for i in range(0, target_prediction.shape[0]):\n",
    "        for j in range(0, target_prediction.shape[1]):\n",
    "            if prediction.values[i, j] > threshold:\n",
    "                recommended_items_at_k.append((i, j))\n",
    "\n",
    "     # Recommended and Relevant items @ k (Intersection)\n",
    "    recomm_and_relevant_items_at_k = list(set(relevant_items) & set(recommended_items_at_k))\n",
    "\n",
    "    # Compute Precision @ K\n",
    "    precision_at_k = len(recomm_and_relevant_items_at_k) / len(recommended_items_at_k)\n",
    "\n",
    "    print(\"Precision at k={}, for prediction using metric {}, is: {}\".format(k, metric, precision_at_k))\n",
    "\n",
    "    # Compute Recall @ K\n",
    "    recall_at_k = len(recomm_and_relevant_items_at_k) / len(relevant_items)\n",
    "\n",
    "    print(\"Recall at k={} for prediction using metric {}, is: {}\".format(k, metric, recall_at_k))\n",
    "\n",
    "    # Compute F1 score @ K\n",
    "    f1_score_at_k = 2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k)\n",
    "\n",
    "    print(\"F1 Score at k={}, for prediction using metric {}, is: {}\".format(k, metric, f1_score_at_k))\n",
    "    return predictions_to_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3ae09cb1-ab03-4bfb-b4db-50a987e1d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at k=22, for prediction using metric Content-Based, is: 0.8666666666666667\n",
      "Recall at k=22 for prediction using metric Content-Based, is: 0.5909090909090909\n",
      "F1 Score at k=22, for prediction using metric Content-Based, is: 0.7027027027027029\n"
     ]
    }
   ],
   "source": [
    "content_based_predictions = evaluate_predictions(aux, my_rate_books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655a0871-52d3-40be-b214-a5036bf92735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_based_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcontent_based_predictions\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_based_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "len(content_based_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "635b89d4-d83f-4da9-8c95-5897ad2b372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527d9a5-dd39-4944-a3af-c7804ec43da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
